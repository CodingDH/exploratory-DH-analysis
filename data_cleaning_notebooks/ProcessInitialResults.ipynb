{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Initial Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from data_generation_scripts.utils import check_rate_limit, check_add_orgs, check_add_repos, check_add_users, check_for_joins_in_older_queries, read_combine_files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've run `generate_expanded_search_data.py` and then `check_clean_search_results.py` you'll have a series of files in the `data/` directory that contain the results of your search. This notebook will help you process those results into a single file that can be used for analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of how to run `generate_expanded_search_data.py`:\n",
    "\n",
    "```python3\n",
    "rates_df = check_rate_limit()\n",
    "initial_repo_output_path = \"../data/repo_data/\"\n",
    "repo_output_path = \"../data/large_files/entity_files/repos_dataset.csv\"\n",
    "repo_join_output_path = \"../data/large_files/join_files/search_queries_repo_join_dataset.csv\"\n",
    "\n",
    "initial_user_output_path = \"../data/user_data/\"\n",
    "user_output_path = \"../data/entity_files/users_dataset.csv\"\n",
    "user_join_output_path = \"../data/join_files/search_queries_user_join_dataset.csv\"\n",
    "load_existing_data = False\n",
    "overwrite_existing_temp_files = False\n",
    "org_output_path = \"../data/entity_files/orgs_dataset.csv\"\n",
    "\n",
    "get_initial_search_datasets(rates_df, initial_repo_output_path,  repo_output_path, repo_join_output_path, initial_user_output_path, user_output_path, user_join_output_path, org_output_path, overwrite_existing_temp_files, load_existing_data)\n",
    "```\n",
    "\n",
    "And then just run `check_clean_search_results.py` "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Initial Core Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.read_csv(\"../data/entity_files/users_dataset.csv\")\n",
    "repo_df = pd.read_csv(\"../data/large_files/entity_files/repos_dataset.csv\", low_memory=False)\n",
    "org_df = pd.read_csv(\"../data/entity_files/orgs_dataset.csv\", low_memory=False)\n",
    "search_queries_repo_join_df = pd.read_csv(\"../data/derived_files/updated_search_queries_repo_join_subset_dh_dataset.csv\")\n",
    "search_queries_user_join_df = pd.read_csv(\n",
    "    \"../data/derived_files/updated_search_queries_user_join_subset_dh_dataset.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial core datasets will be comprised of the following:\n",
    "\n",
    "- `core_repos`: A list of all repos that were returned by the search query\n",
    "- `core_users`: A list of all users that were returned by the search query\n",
    "- `core_orgs`: A list of all orgs that were returned by the search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_join_output_path = \"../data/large_files/join_files/search_queries_repo_join_dataset.csv\"\n",
    "user_join_output_path = \"../data/join_files/search_queries_user_join_dataset.csv\"\n",
    "join_unique_field = 'search_query'\n",
    "repo_filter_fields = ['full_name', 'cleaned_search_query']\n",
    "user_filter_fields = ['login', 'cleaned_search_query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_repo_join_output_path = \"../data/large_files/join_files/search_queries_repo_join_dataset.csv\"\n",
    "existing_repo_join_output_path = \"../data/derived_files/updated_search_queries_repo_join_subset_dh_dataset.csv\"\n",
    "\n",
    "initial_user_join_output_path = \"../data/join_files/search_queries_user_join_dataset.csv\"\n",
    "existing_user_join_output_path = \"../data/derived_files/updated_search_queries_user_join_subset_dh_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_terms = ['Digital Humanities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_queries_repo_df = search_queries_repo_join_df.copy()\n",
    "search_queries_user_df = search_queries_user_join_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_queries_user_df['cleaned_search_query'] = search_queries_user_df['search_query'].str.replace('%22', '\"').str.replace('\"', '').str.replace('%3A', ':').str.split('&page').str[0]\n",
    "search_queries_repo_df['cleaned_search_query'] = search_queries_repo_df['search_query'].str.replace('%22', '\"').str.replace('\"', '').str.replace('%3A', ':').str.split('&page').str[0]\n",
    "\n",
    "updated_search_queries_repo_df = check_for_joins_in_older_queries(repo_join_output_path, search_queries_repo_df, join_unique_field, repo_filter_fields, subset_terms)\n",
    "updated_search_queries_user_df = check_for_joins_in_older_queries(user_join_output_path, search_queries_user_df, join_unique_field, user_filter_fields, subset_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_search_queries_repo_df = pd.read_csv(initial_repo_join_output_path)\n",
    "initial_search_queries_user_df  = pd.read_csv(initial_user_join_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_search_queries_user_df['cleaned_search_query'] = initial_search_queries_user_df['search_query'].str.replace('%22', '\"').str.replace('\"', '').str.replace('%3A', ':').str.split('&page').str[0]\n",
    "initial_search_queries_repo_df['cleaned_search_query'] = initial_search_queries_repo_df['search_query'].str.replace('%22', '\"').str.replace('\"', '').str.replace('%3A', ':').str.split('&page').str[0]\n",
    "\n",
    "initial_search_queries_repo_df = initial_search_queries_repo_df[initial_search_queries_repo_df.search_term_source.isin(subset_terms)]\n",
    "initial_search_queries_user_df = initial_search_queries_user_df[initial_search_queries_user_df.search_term_source.isin(subset_terms)]\n",
    "\n",
    "\n",
    "search_queries_repo_df = pd.concat([updated_search_queries_repo_df, initial_search_queries_repo_df])\n",
    "search_queries_user_df = pd.concat([updated_search_queries_user_df, initial_search_queries_user_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_language_data(rows: pd.DataFrame, is_repo: bool) -> pd.DataFrame:\n",
    "    \"\"\"Fill in the missing language data for the search queries data.\n",
    "    :param rows: The search queries data\n",
    "    :type rows: pandas.DataFrame\n",
    "    :param is_repo: Whether the search queries data is for repos or users\n",
    "    :type is_repo: bool\n",
    "    :return: The search queries data with the missing language data filled in\"\"\"\n",
    "    if len(rows[rows.finalized_language.notna()]) == 0:\n",
    "        entity_type = 'Repo' if is_repo else 'User'\n",
    "        field = 'full_name' if is_repo else 'login'\n",
    "        print(f\"No finalized language {len(rows)}, {rows.finalized_language.unique()}, {entity_type} {rows[rows[field].notna()][field].unique()[0]}\") \n",
    "    detected_language = rows[rows.detected_language.notnull()].detected_language.unique()\n",
    "    rows.detected_language = detected_language[0] if len(detected_language) > 0 else None\n",
    "    detected_language_confidence = rows[rows.detected_language_confidence.notnull()].detected_language_confidence.unique()\n",
    "    if len(detected_language_confidence) > 1:\n",
    "        detected_language_confidence = [rows[rows.detected_language_confidence.notnull()].detected_language_confidence.max()]\n",
    "    rows.detected_language_confidence = detected_language_confidence[0] if len(detected_language_confidence) > 0 else None\n",
    "    finalized_language = rows[rows.finalized_language.notna()].finalized_language.unique()\n",
    "    if len(finalized_language) > 1:\n",
    "        print(finalized_language)\n",
    "        finalized_language = [lang for lang in finalized_language if lang != None]\n",
    "        print(finalized_language)\n",
    "    rows.finalized_language = finalized_language[0] if len(finalized_language) > 0 else None\n",
    "    keep_resource = rows[rows.keep_resource.notna()].keep_resource.unique()\n",
    "    rows.keep_resource = keep_resource[0] if len(keep_resource) > 0 else None\n",
    "    if (len(detected_language) > 1) | (len(detected_language_confidence) > 1) | (len(finalized_language) > 1) | (len(keep_resource) > 1):\n",
    "        entity_type = 'Repo' if is_repo else 'User'\n",
    "        field = 'full_name' if is_repo else 'login'\n",
    "        unique_id = rows[rows[field].notna()][field].unique()[0]\n",
    "        print(f\"{entity_type} {unique_id}: Detected: {len(detected_language)}, Confidence: {detected_language_confidence}, Finalized: {len(finalized_language)}, Keep: {len(keep_resource)}\")\n",
    " \n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fill missing language data:  13%|█▎        | 119/926 [00:00<00:01, 614.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No finalized language 4, [nan], User 2enyoasamoah\n",
      "No finalized language 6, [nan], User ANAVDUTT\n",
      "No finalized language 16, [nan], User BCDH\n",
      "No finalized language 16, [nan], User BYU-ODH\n",
      "No finalized language 6, [nan], User BeatriceVaienti\n",
      "No finalized language 10, [nan], User CDH-DevTeam\n",
      "No finalized language 16, [nan], User CDH-SC\n",
      "No finalized language 16, [nan], User CNMATDH\n",
      "No finalized language 16, [nan], User CVCEeu-dh\n",
      "No finalized language 6, [nan], User ChloeNewman\n",
      "No finalized language 16, [nan], User DH-Cologne\n",
      "No finalized language 6, [nan], User DHCodeReview\n",
      "No finalized language 16, [nan], User DHLUW\n",
      "No finalized language 16, [nan], User DHSIG\n",
      "No finalized language 16, [nan], User DIGI-VUB\n",
      "No finalized language 6, [nan], User DaKuschel\n",
      "No finalized language 12, [nan], User Digitaalhumanitaaria\n",
      "No finalized language 16, [nan], User Digital-Humanities-Centre\n",
      "No finalized language 16, [nan], User Digital-Humanities-Creative-Lab\n",
      "No finalized language 16, [nan], User DigitalHumanitiesLabs\n",
      "No finalized language 6, [nan], User DigitalHumanitiesMinorVU\n",
      "No finalized language 16, [nan], User DigitalHumanitiesNow\n",
      "No finalized language 4, [nan], User DrPhilipAShaw\n",
      "No finalized language 6, [nan], User E-Westphalen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fill missing language data:  32%|███▏      | 292/926 [00:00<00:00, 775.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No finalized language 6, [nan], User FrancescoDiCursi\n",
      "No finalized language 16, [nan], User GhentCDH\n",
      "No finalized language 16, [nan], User GroningenDH\n",
      "No finalized language 6, [nan], User GusRiva\n",
      "No finalized language 18, [nan], User HumanidadesDigitales\n",
      "No finalized language 6, [nan], User JajwalyaRK\n",
      "No finalized language 6, [nan], User JillBriggeman\n",
      "No finalized language 6, [nan], User Kalo9603\n",
      "No finalized language 16, [nan], User KeystoneDH\n",
      "No finalized language 16, [nan], User King-s-Digital-Humanities\n",
      "No finalized language 16, [nan], User LoyolaChicagoDigitalHumanities\n",
      "No finalized language 16, [nan], User M-L-D-H\n",
      "No finalized language 16, [nan], User Maynooth-Center-for-Digital-Humanities\n",
      "No finalized language 6, [nan], User MescoCoder\n",
      "No finalized language 16, [nan], User NYUADDH\n",
      "No finalized language 6, [nan], User Princeton-CDH\n",
      "No finalized language 16, [nan], User Python-Tutorials-for-Digital-Humanities\n",
      "No finalized language 6, [nan], User RemoGrillo\n",
      "No finalized language 6, [nan], User RusBilot\n",
      "No finalized language 16, [nan], User RyersonCDH\n",
      "No finalized language 16, [nan], User SharedTasksInTheDH\n",
      "No finalized language 6, [nan], User Sourasky-DHLAB\n",
      "No finalized language 18, [nan], User Taller-Abierto-de-Humanidades-Digitales\n",
      "No finalized language 6, [nan], User UACDH\n",
      "No finalized language 16, [nan], User UTDigitalHumanities\n",
      "No finalized language 6, [nan], User ValentineCB\n",
      "No finalized language 6, [nan], User Vneb\n",
      "No finalized language 6, [nan], User XiaoyanYangAlice\n",
      "No finalized language 16, [nan], User YaleDHLab\n",
      "No finalized language 16, [nan], User acdh-oeaw\n",
      "No finalized language 16, [nan], User adholibdh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fill missing language data:  49%|████▊     | 450/926 [00:00<00:00, 774.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No finalized language 6, [nan], User alice13510\n",
      "No finalized language 6, [nan], User andreaspataro\n",
      "No finalized language 6, [nan], User angstigone\n",
      "No finalized language 16, [nan], User bcdhbonn\n",
      "No finalized language 6, [nan], User casglur\n",
      "No finalized language 16, [nan], User comp-int-hum\n",
      "No finalized language 6, [nan], User danieltepavac\n",
      "No finalized language 16, [nan], User dh-trier\n",
      "No finalized language 16, [nan], User dhc-barnard\n",
      "No finalized language 16, [nan], User dhc-uob\n",
      "No finalized language 16, [nan], User dhcbalamand\n",
      "No finalized language 16, [nan], User dhdc\n",
      "No finalized language 16, [nan], User dhh16\n",
      "No finalized language 16, [nan], User dhh17\n",
      "No finalized language 16, [nan], User dhh18\n",
      "No finalized language 16, [nan], User dhh19\n",
      "No finalized language 16, [nan], User dhh21\n",
      "No finalized language 16, [nan], User dhh22\n",
      "No finalized language 16, [nan], User dhhse\n",
      "No finalized language 6, [nan], User dhinfra-at\n",
      "No finalized language 16, [nan], User dhlab-epfl\n",
      "No finalized language 16, [nan], User dhll\n",
      "No finalized language 16, [nan], User dhsocal\n",
      "No finalized language 16, [nan], User dhtaxonomy\n",
      "No finalized language 16, [nan], User digitalhumanities\n",
      "No finalized language 16, [nan], User digitalhumanitieshub\n",
      "No finalized language 12, [nan], User ditah-at\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fill missing language data:  67%|██████▋   | 621/926 [00:00<00:00, 819.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No finalized language 6, [nan], User egibso10\n",
      "No finalized language 6, [nan], User elizastuglik\n",
      "No finalized language 6, [nan], User eugestumm\n",
      "No finalized language 6, [nan], User exploratoriohd\n",
      "No finalized language 6, [nan], User gdmeo\n",
      "No finalized language 16, [nan], User go-dh\n",
      "No finalized language 6, [nan], User gu-gridh\n",
      "No finalized language 6, [nan], User hermann-bahr\n",
      "No finalized language 16, [nan], User hridigital\n",
      "No finalized language 6, [nan], User httpschiara\n",
      "No finalized language 4, [nan], User hvm-uu\n",
      "No finalized language 16, [nan], User idhmc-tamu\n",
      "No finalized language 12, [nan], User idrhku\n",
      "No finalized language 6, [nan], User imlabormitlea-code\n",
      "No finalized language 6, [nan], User iserenko\n",
      "No finalized language 6, [nan], User joshuavachon25\n",
      "No finalized language 6, [nan], User juanfuc\n",
      "No finalized language 6, [nan], User justinwigard\n",
      "No finalized language 6, [nan], User karljazz74\n",
      "No finalized language 6, [nan], User kbadly1\n",
      "No finalized language 6, [nan], User kfitz\n",
      "No finalized language 6, [nan], User kochanovskayaanna\n",
      "No finalized language 6, [nan], User lab-humanidades-digitales-pucp\n",
      "No finalized language 6, [nan], User labiu\n",
      "No finalized language 6, [nan], User labriunesp\n",
      "No finalized language 16, [nan], User larhud\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fill missing language data:  87%|████████▋ | 804/926 [00:01<00:00, 865.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No finalized language 18, [nan], User linhd-dev\n",
      "No finalized language 6, [nan], User lisateichmann\n",
      "No finalized language 4, [nan], User lunaparrafos\n",
      "No finalized language 6, [nan], User lyang02\n",
      "No finalized language 6, [nan], User maehr\n",
      "No finalized language 18, [nan], User maestriahd\n",
      "No finalized language 6, [nan], User manny-rocha\n",
      "No finalized language 6, [nan], User martasoricetti\n",
      "No finalized language 6, [nan], User mathewjordan\n",
      "No finalized language 16, [nan], User matrix-msu\n",
      "No finalized language 6, [nan], User michaelgfalk\n",
      "No finalized language 2, [nan], User ngonthier\n",
      "No finalized language 6, [nan], User oengin15\n",
      "No finalized language 6, [nan], User olgagolgan\n",
      "No finalized language 6, [nan], User pbd84\n",
      "No finalized language 16, [nan], User princetoncdh\n",
      "No finalized language 18, [nan], User redcolhd\n",
      "No finalized language 6, [nan], User skotheim9\n",
      "No finalized language 6, [nan], User t-lini\n",
      "No finalized language 16, [nan], User ucdh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fill missing language data:  97%|█████████▋| 900/926 [00:01<00:00, 890.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No finalized language 16, [nan], User usf-dh\n",
      "No finalized language 6, [nan], User valrighe\n",
      "No finalized language 16, [nan], User villaitatti\n",
      "No finalized language 16, [nan], User wludh\n",
      "No finalized language 2, [nan], User yueyue4359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fill missing language data: 100%|██████████| 926/926 [00:01<00:00, 665.86it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas(desc=\"Fill missing language data\")\n",
    "cleaned_search_queries_repo_df = search_queries_repo_df.groupby(['full_name']).progress_apply(fill_missing_language_data, is_repo=True)\n",
    "clear_output(wait=True)\n",
    "cleaned_search_queries_user_df = search_queries_user_df.groupby(['login']).progress_apply(fill_missing_language_data, is_repo=False)\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_search_queries_user_df['cleaned_search_query'] = cleaned_search_queries_user_df['search_query'].str.replace('%22', '\"').str.replace('\"', '').str.replace('%3A', ':').str.split('&page').str[0]\n",
    "cleaned_search_queries_repo_df['cleaned_search_query'] = cleaned_search_queries_repo_df['search_query'].str.replace('%22', '\"').str.replace('\"', '').str.replace('%3A', ':').str.split('&page').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_search_queries_repo_df.loc[cleaned_search_queries_repo_df.search_query_time.isna(), 'search_query_time'] = \"2022-10-10\"\n",
    "cleaned_search_queries_repo_df['search_query_time'] = pd.to_datetime(cleaned_search_queries_repo_df['search_query_time'], errors='coerce')\n",
    "cleaned_search_queries_repo_df = cleaned_search_queries_repo_df.sort_values(by=['search_query_time'], ascending=False).drop_duplicates(subset=['full_name', 'cleaned_search_query'], keep='first')\n",
    "\n",
    "cleaned_search_queries_user_df.loc[cleaned_search_queries_user_df.search_query_time.isna(), 'search_query_time'] = \"2022-10-10\"\n",
    "cleaned_search_queries_user_df['search_query_time'] = pd.to_datetime(cleaned_search_queries_user_df['search_query_time'], errors='coerce')\n",
    "cleaned_search_queries_user_df = cleaned_search_queries_user_df.sort_values(by=['search_query_time'], ascending=False).drop_duplicates(subset=['login','cleaned_search_query'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_results(search_queries_repo_df: pd.DataFrame, search_queries_user_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Fix the results of the search queries to ensure that the results are correct.\n",
    "    :param search_queries_repo_df: The search queries data for repos\n",
    "    :type search_queries_repo_df: pandas.DataFrame\n",
    "    :param search_queries_user_df: The search queries data for users\n",
    "    :type search_queries_user_df: pandas.DataFrame\n",
    "    :return: The fixed search queries data\"\"\"\n",
    "\n",
    "    fix_repo_queries = search_queries_repo_df[(search_queries_repo_df.cleaned_search_query.str.contains('q=\"Humanities\"')) & (search_queries_repo_df.search_term_source == \"Digital Humanities\")]\n",
    "    fix_user_queries = search_queries_user_df[(search_queries_user_df.cleaned_search_query.str.contains('q=\"Humanities\"')) & (search_queries_user_df.search_term_source == \"Digital Humanities\")]\n",
    "    if len(fix_repo_queries) > 0:\n",
    "        replace_repo_queries = search_queries_repo_df[(search_queries_repo_df.full_name.isin(fix_repo_queries.full_name)) & (search_queries_repo_df.search_term_source == \"Digital Humanities\")][['full_name', 'search_query']]\n",
    "        search_queries_repo_df.loc[search_queries_repo_df.full_name.isin(fix_repo_queries.full_name), 'cleaned_search_query'] = search_queries_repo_df.loc[search_queries_repo_df.full_name.isin(fix_repo_queries.full_name), 'full_name'].map(replace_repo_queries.set_index('full_name').to_dict()['search_query'])\n",
    "        \n",
    "    if len(fix_user_queries) > 0:\n",
    "        replace_user_queries = search_queries_user_df[(search_queries_user_df.full_name.isin(fix_user_queries.login)) & (search_queries_user_df.search_term_source == \"Digital Humanities\")][['login', 'search_query']]\n",
    "        search_queries_user_df.loc[search_queries_user_df.login.isin(fix_user_queries.login), 'cleaned_search_query'] = search_queries_user_df.loc[search_queries_user_df.login.isin(fix_user_queries.login), 'login'].map(replace_user_queries.set_index('login').to_dict()['search_query'])\n",
    "    return search_queries_repo_df, search_queries_user_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_queries_repo_df, search_queries_user_df = fix_results(search_queries_repo_df, search_queries_user_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_search_queries_user_df.duplicated(subset=['login', 'cleaned_search_query']).sum(), cleaned_search_queries_repo_df.duplicated(subset=['full_name', 'cleaned_search_query']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 314)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_search_queries_user_df.finalized_language.isna().sum(), cleaned_search_queries_repo_df.finalized_language.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generation_scripts.generate_translations import check_detect_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_languages(search_df: pd.DataFrame, search_type: str) -> pd.DataFrame:\n",
    "    \"\"\"Get the languages for the search queries data.\n",
    "    :param search_df: The search queries data for repos\n",
    "    :type search_df: pandas.DataFrame\n",
    "    :param search_type: The type of search queries data\n",
    "    :type search_type: str\n",
    "    :return: The search queries data with the languages added\"\"\"\n",
    "    tqdm.pandas(desc='Detecting language')\n",
    "    if 'repo' in search_type:\n",
    "        search_df.description = search_df.description.fillna('')\n",
    "    else:\n",
    "        search_df.bio = search_df.bio.fillna('')\n",
    "    search_df = search_df.progress_apply(check_detect_language, axis=1, is_repo=True)\n",
    "    return search_df\n",
    "\n",
    "def clean_languages(search_df: pd.DataFrame, join_field: str) -> pd.DataFrame:\n",
    "    \"\"\"Clean the languages for the search queries data.\n",
    "    :param search_df: The search queries data for repos\n",
    "    :type search_df: pandas.DataFrame\n",
    "    :param join_field: The field to join the search queries data to the repo data\n",
    "    :type join_field: str\n",
    "    :return: The search queries data with the languages cleaned\"\"\"\n",
    "    english_langs = 'en, ny, ha, ig, lb, mg, sm, sn, st, tl, yo'\n",
    "    english_langs = english_langs.split(', ')\n",
    "    search_df.loc[(search_df.detected_language.isin(\n",
    "        english_langs)) & (search_df.finalized_language.isna()), 'finalized_language'] = search_df.detected_language\n",
    "    search_df.loc[(search_df.natural_language == search_df.detected_language) & (search_df.finalized_language.isna()),\n",
    "                  'finalized_language'] = search_df.detected_language\n",
    "    needs_language = search_df[(search_df.detected_language.str.contains('zh', na=False)) & (search_df.natural_language == 'zh') & (search_df.finalized_language.isna())]\n",
    "    if len(needs_language) > 0:\n",
    "        search_df.loc[(search_df.detected_language.str.contains('zh', na=False)) & (search_df.natural_language == 'zh'), 'finalized_language'] = search_df.loc[(search_df.detected_language.str.contains('zh', na=False)) & (search_df.natural_language == 'zh'), 'detected_language']\n",
    "    needs_language =  search_df[(search_df.natural_language.str.contains('fr')) & (search_df.detected_language.str.contains('fr')) & (search_df.finalized_language.isna())]\n",
    "    if len(needs_language) > 0:\n",
    "        search_df.loc[(search_df.natural_language.str.contains('fr')) & (search_df.detected_language.str.contains('fr')), 'finalized_language'] = 'fr'\n",
    "    needs_language = search_df[(search_df.natural_language == 'xh, zu') & (search_df.finalized_language.isna())]\n",
    "    if len(needs_language) > 0:\n",
    "        search_df.loc[(search_df.natural_language == 'xh, zu') & (search_df.finalized_language.isna()), 'finalized_language'] = search_df.loc[(search_df.natural_language == 'xh, zu') & (search_df.detected_language.notna()), 'detected_language']\n",
    "    search_df.loc[(search_df.finalized_language.isna()) & (\n",
    "        search_df.detected_language_confidence < 0.5), 'finalized_language'] = None\n",
    "    if join_field == 'full_name':\n",
    "\n",
    "        search_df.loc[(search_df.finalized_language.isna()) & (\n",
    "        search_df.description.str.len() < 30), 'finalized_language'] = None\n",
    "        search_df.loc[(search_df.detected_language.isna()) & (\n",
    "            search_df.description.isna()) & (search_df.finalized_language.isna()), 'finalized_language'] = None\n",
    "        search_df.loc[(search_df.detected_language.isna()) & (\n",
    "            search_df.description.isna()) & (search_df['size'] < 1) & (search_df.finalized_language.isna()), 'keep_resource'] = False\n",
    "    if join_field == 'login':\n",
    "        search_df.loc[(search_df.finalized_language.isna()) & (\n",
    "            search_df.bio.str.len() < 30), 'finalized_language'] = None\n",
    "        search_df.loc[(search_df.detected_language.isna()) & (\n",
    "            search_df.bio.isna() & (search_df.finalized_language.isna())), 'finalized_language'] = None\n",
    "    return search_df\n",
    "\n",
    "def clean_search_queries_data(search_df: object, join_field: str, search_type: str) -> object:\n",
    "    \"\"\"Clean the search queries data and try to determine as much as possible the exact language using automated language detection and natural language processing.\n",
    "    :param search_df: The search queries data\n",
    "    :type search_df: pandas.DataFrame\n",
    "    :param join_field: The field to join the search queries data to the repo data\n",
    "    :type join_field: str\n",
    "    :param search_type: The type of search queries data\n",
    "    :type search_type: str\n",
    "    :return: The cleaned search queries data\n",
    "    :rtype: pandas.DataFrame\"\"\"\n",
    "    \n",
    "    search_df = search_df.drop_duplicates(\n",
    "        subset=[join_field, 'cleaned_search_query'])\n",
    "    \n",
    "    if 'keep_resource' not in search_df.columns:\n",
    "        search_df['keep_resource'] = True\n",
    "    else:\n",
    "        search_df.loc[search_df.keep_resource == 'None'] = None\n",
    "    \n",
    "\n",
    "    if 'finalized_language' not in search_df.columns:\n",
    "        search_df['finalized_language'] = None\n",
    "    else:\n",
    "        search_df.loc[search_df.finalized_language == 'None'] = None\n",
    "    \n",
    "    if 'detected_language' not in search_df.columns:\n",
    "        search_df = get_languages(search_df, search_type)\n",
    "        search_df = clean_languages(search_df, join_field)\n",
    "    else:\n",
    "        subset_search_df = search_df[(search_df.detected_language.isna()) & (search_df.finalized_language.isna())]\n",
    "        existing_search_df = search_df[(search_df.detected_language.notna()) & (search_df.finalized_language.notna())]\n",
    "        print(len(subset_search_df), len(existing_search_df))\n",
    "        # if len(subset_search_df) > 0:\n",
    "        #     subset_search_df = get_languages(subset_search_df, search_type)\n",
    "\n",
    "        # search_df = pd.concat([existing_search_df, subset_search_df])\n",
    "        # search_df = clean_languages(search_df, join_field)\n",
    "    return search_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting language:  14%|█▎        | 554/4080 [00:14<01:36, 36.48it/s]"
     ]
    }
   ],
   "source": [
    "search_queries_repo_df = clean_search_queries_data(search_queries_repo_df, 'full_name', 'repo')\n",
    "search_queries_user_df = clean_search_queries_data(search_queries_user_df, 'login', 'user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7790"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.concat([search_queries_user_join_df, older_join_df])\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['cleaned_search_query_time'] = None\n",
    "test.loc[test.cleaned_search_query_time.isna(), 'cleaned_search_query_time'] = \"2022-10-10\"\n",
    "test.loc[test.search_query_time.notna(), 'cleaned_search_query_time'] = test.loc[test.search_query_time.notna(), 'search_query_time']\n",
    "test['cleaned_search_query_time'] = pd.to_datetime(test['cleaned_search_query_time'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['cleaned_search_query'] = test['search_query'].str.replace('%22', '\"').str.replace('\"', '').str.replace('%3A', ':').str.split('&page').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = test.sort_values(by=['cleaned_search_query_time'], ascending=False).drop_duplicates(subset=subset_fields, keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(797, 930)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = search_queries_user_join_df.copy()\n",
    "older_df = test2.copy()\n",
    "len(df), len(older_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_older_df = older_df[['login', 'cleaned_search_query']].reset_index(drop=True)\n",
    "subset_older_df = subset_older_df[subset_older_df.login.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = df[['login', 'cleaned_search_query']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df['type_of_join'] = \"new\"\n",
    "subset_older_df['type_of_join'] = \"old\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(subset_df, subset_older_df, on=['login', 'cleaned_search_query'], how='outer', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = merged_df[merged_df._merge == 'right_only']\n",
    "\n",
    "double_check = missing_values[subset_fields]\n",
    "combined_condition = np.ones(len(older_df), dtype=bool)\n",
    "for field in subset_fields:\n",
    "    combined_condition = combined_condition & older_df[field].isin(double_check[field])\n",
    "older_df['double_check'] = np.where(combined_condition, 1, 0)\n",
    "final_missing_values = older_df[(older_df.double_check == 1) & (older_df[subset_fields[0]].isin(double_check[subset_fields[0]]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>login</th>\n",
       "      <th>id</th>\n",
       "      <th>node_id</th>\n",
       "      <th>avatar_url</th>\n",
       "      <th>gravatar_id</th>\n",
       "      <th>url</th>\n",
       "      <th>html_url</th>\n",
       "      <th>followers_url</th>\n",
       "      <th>following_url</th>\n",
       "      <th>gists_url</th>\n",
       "      <th>...</th>\n",
       "      <th>hooks_url</th>\n",
       "      <th>issues_url</th>\n",
       "      <th>members_url</th>\n",
       "      <th>public_members_url</th>\n",
       "      <th>description</th>\n",
       "      <th>is_verified</th>\n",
       "      <th>has_organization_projects</th>\n",
       "      <th>has_repository_projects</th>\n",
       "      <th>double_check</th>\n",
       "      <th>cleaned_search_query_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>dhtaxonomy</td>\n",
       "      <td>6716560.0</td>\n",
       "      <td>MDEyOk9yZ2FuaXphdGlvbjY3MTY1NjA=</td>\n",
       "      <td>https://avatars.githubusercontent.com/u/671656...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.github.com/users/dhtaxonomy</td>\n",
       "      <td>https://github.com/dhtaxonomy</td>\n",
       "      <td>https://api.github.com/users/dhtaxonomy/followers</td>\n",
       "      <td>https://api.github.com/users/dhtaxonomy/follow...</td>\n",
       "      <td>https://api.github.com/users/dhtaxonomy/gists{...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>CDH-SC</td>\n",
       "      <td>10634990.0</td>\n",
       "      <td>MDEyOk9yZ2FuaXphdGlvbjEwNjM0OTkw</td>\n",
       "      <td>https://avatars.githubusercontent.com/u/106349...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.github.com/users/CDH-SC</td>\n",
       "      <td>https://github.com/CDH-SC</td>\n",
       "      <td>https://api.github.com/users/CDH-SC/followers</td>\n",
       "      <td>https://api.github.com/users/CDH-SC/following{...</td>\n",
       "      <td>https://api.github.com/users/CDH-SC/gists{/gis...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>adholibdh</td>\n",
       "      <td>17990648.0</td>\n",
       "      <td>MDEyOk9yZ2FuaXphdGlvbjE3OTkwNjQ4</td>\n",
       "      <td>https://avatars.githubusercontent.com/u/179906...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.github.com/users/adholibdh</td>\n",
       "      <td>https://github.com/adholibdh</td>\n",
       "      <td>https://api.github.com/users/adholibdh/followers</td>\n",
       "      <td>https://api.github.com/users/adholibdh/followi...</td>\n",
       "      <td>https://api.github.com/users/adholibdh/gists{/...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>dhh21</td>\n",
       "      <td>83238279.0</td>\n",
       "      <td>MDEyOk9yZ2FuaXphdGlvbjgzMjM4Mjc5</td>\n",
       "      <td>https://avatars.githubusercontent.com/u/832382...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.github.com/users/dhh21</td>\n",
       "      <td>https://github.com/dhh21</td>\n",
       "      <td>https://api.github.com/users/dhh21/followers</td>\n",
       "      <td>https://api.github.com/users/dhh21/following{/...</td>\n",
       "      <td>https://api.github.com/users/dhh21/gists{/gist...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>idrhku</td>\n",
       "      <td>17508677.0</td>\n",
       "      <td>MDEyOk9yZ2FuaXphdGlvbjE3NTA4Njc3</td>\n",
       "      <td>https://avatars.githubusercontent.com/u/175086...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.github.com/users/idrhku</td>\n",
       "      <td>https://github.com/idrhku</td>\n",
       "      <td>https://api.github.com/users/idrhku/followers</td>\n",
       "      <td>https://api.github.com/users/idrhku/following{...</td>\n",
       "      <td>https://api.github.com/users/idrhku/gists{/gis...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>XiaoyanYangAlice</td>\n",
       "      <td>121414040.0</td>\n",
       "      <td>U_kgDOBzyhmA</td>\n",
       "      <td>https://avatars.githubusercontent.com/u/121414...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.github.com/users/XiaoyanYangAlice</td>\n",
       "      <td>https://github.com/XiaoyanYangAlice</td>\n",
       "      <td>https://api.github.com/users/XiaoyanYangAlice/...</td>\n",
       "      <td>https://api.github.com/users/XiaoyanYangAlice/...</td>\n",
       "      <td>https://api.github.com/users/XiaoyanYangAlice/...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3785</th>\n",
       "      <td>ngonthier</td>\n",
       "      <td>23408564.0</td>\n",
       "      <td>MDQ6VXNlcjIzNDA4NTY0</td>\n",
       "      <td>https://avatars.githubusercontent.com/u/234085...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.github.com/users/ngonthier</td>\n",
       "      <td>https://github.com/ngonthier</td>\n",
       "      <td>https://api.github.com/users/ngonthier/followers</td>\n",
       "      <td>https://api.github.com/users/ngonthier/followi...</td>\n",
       "      <td>https://api.github.com/users/ngonthier/gists{/...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-11-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3786</th>\n",
       "      <td>yueyue4359</td>\n",
       "      <td>88612363.0</td>\n",
       "      <td>MDQ6VXNlcjg4NjEyMzYz</td>\n",
       "      <td>https://avatars.githubusercontent.com/u/886123...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.github.com/users/yueyue4359</td>\n",
       "      <td>https://github.com/yueyue4359</td>\n",
       "      <td>https://api.github.com/users/yueyue4359/followers</td>\n",
       "      <td>https://api.github.com/users/yueyue4359/follow...</td>\n",
       "      <td>https://api.github.com/users/yueyue4359/gists{...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-11-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3787</th>\n",
       "      <td>hvm-uu</td>\n",
       "      <td>83591395.0</td>\n",
       "      <td>MDQ6VXNlcjgzNTkxMzk1</td>\n",
       "      <td>https://avatars.githubusercontent.com/u/835913...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.github.com/users/hvm-uu</td>\n",
       "      <td>https://github.com/hvm-uu</td>\n",
       "      <td>https://api.github.com/users/hvm-uu/followers</td>\n",
       "      <td>https://api.github.com/users/hvm-uu/following{...</td>\n",
       "      <td>https://api.github.com/users/hvm-uu/gists{/gis...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-11-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>2enyoasamoah</td>\n",
       "      <td>106137379.0</td>\n",
       "      <td>U_kgDOBlOHIw</td>\n",
       "      <td>https://avatars.githubusercontent.com/u/106137...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.github.com/users/2enyoasamoah</td>\n",
       "      <td>https://github.com/2enyoasamoah</td>\n",
       "      <td>https://api.github.com/users/2enyoasamoah/foll...</td>\n",
       "      <td>https://api.github.com/users/2enyoasamoah/foll...</td>\n",
       "      <td>https://api.github.com/users/2enyoasamoah/gist...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-11-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 login           id                           node_id  \\\n",
       "585         dhtaxonomy    6716560.0  MDEyOk9yZ2FuaXphdGlvbjY3MTY1NjA=   \n",
       "593             CDH-SC   10634990.0  MDEyOk9yZ2FuaXphdGlvbjEwNjM0OTkw   \n",
       "599          adholibdh   17990648.0  MDEyOk9yZ2FuaXphdGlvbjE3OTkwNjQ4   \n",
       "568              dhh21   83238279.0  MDEyOk9yZ2FuaXphdGlvbjgzMjM4Mjc5   \n",
       "572             idrhku   17508677.0  MDEyOk9yZ2FuaXphdGlvbjE3NTA4Njc3   \n",
       "...                ...          ...                               ...   \n",
       "1153  XiaoyanYangAlice  121414040.0                      U_kgDOBzyhmA   \n",
       "3785         ngonthier   23408564.0              MDQ6VXNlcjIzNDA4NTY0   \n",
       "3786        yueyue4359   88612363.0              MDQ6VXNlcjg4NjEyMzYz   \n",
       "3787            hvm-uu   83591395.0              MDQ6VXNlcjgzNTkxMzk1   \n",
       "3788      2enyoasamoah  106137379.0                      U_kgDOBlOHIw   \n",
       "\n",
       "                                             avatar_url  gravatar_id  \\\n",
       "585   https://avatars.githubusercontent.com/u/671656...          NaN   \n",
       "593   https://avatars.githubusercontent.com/u/106349...          NaN   \n",
       "599   https://avatars.githubusercontent.com/u/179906...          NaN   \n",
       "568   https://avatars.githubusercontent.com/u/832382...          NaN   \n",
       "572   https://avatars.githubusercontent.com/u/175086...          NaN   \n",
       "...                                                 ...          ...   \n",
       "1153  https://avatars.githubusercontent.com/u/121414...          NaN   \n",
       "3785  https://avatars.githubusercontent.com/u/234085...          NaN   \n",
       "3786  https://avatars.githubusercontent.com/u/886123...          NaN   \n",
       "3787  https://avatars.githubusercontent.com/u/835913...          NaN   \n",
       "3788  https://avatars.githubusercontent.com/u/106137...          NaN   \n",
       "\n",
       "                                                url  \\\n",
       "585         https://api.github.com/users/dhtaxonomy   \n",
       "593             https://api.github.com/users/CDH-SC   \n",
       "599          https://api.github.com/users/adholibdh   \n",
       "568              https://api.github.com/users/dhh21   \n",
       "572             https://api.github.com/users/idrhku   \n",
       "...                                             ...   \n",
       "1153  https://api.github.com/users/XiaoyanYangAlice   \n",
       "3785         https://api.github.com/users/ngonthier   \n",
       "3786        https://api.github.com/users/yueyue4359   \n",
       "3787            https://api.github.com/users/hvm-uu   \n",
       "3788      https://api.github.com/users/2enyoasamoah   \n",
       "\n",
       "                                 html_url  \\\n",
       "585         https://github.com/dhtaxonomy   \n",
       "593             https://github.com/CDH-SC   \n",
       "599          https://github.com/adholibdh   \n",
       "568              https://github.com/dhh21   \n",
       "572             https://github.com/idrhku   \n",
       "...                                   ...   \n",
       "1153  https://github.com/XiaoyanYangAlice   \n",
       "3785         https://github.com/ngonthier   \n",
       "3786        https://github.com/yueyue4359   \n",
       "3787            https://github.com/hvm-uu   \n",
       "3788      https://github.com/2enyoasamoah   \n",
       "\n",
       "                                          followers_url  \\\n",
       "585   https://api.github.com/users/dhtaxonomy/followers   \n",
       "593       https://api.github.com/users/CDH-SC/followers   \n",
       "599    https://api.github.com/users/adholibdh/followers   \n",
       "568        https://api.github.com/users/dhh21/followers   \n",
       "572       https://api.github.com/users/idrhku/followers   \n",
       "...                                                 ...   \n",
       "1153  https://api.github.com/users/XiaoyanYangAlice/...   \n",
       "3785   https://api.github.com/users/ngonthier/followers   \n",
       "3786  https://api.github.com/users/yueyue4359/followers   \n",
       "3787      https://api.github.com/users/hvm-uu/followers   \n",
       "3788  https://api.github.com/users/2enyoasamoah/foll...   \n",
       "\n",
       "                                          following_url  \\\n",
       "585   https://api.github.com/users/dhtaxonomy/follow...   \n",
       "593   https://api.github.com/users/CDH-SC/following{...   \n",
       "599   https://api.github.com/users/adholibdh/followi...   \n",
       "568   https://api.github.com/users/dhh21/following{/...   \n",
       "572   https://api.github.com/users/idrhku/following{...   \n",
       "...                                                 ...   \n",
       "1153  https://api.github.com/users/XiaoyanYangAlice/...   \n",
       "3785  https://api.github.com/users/ngonthier/followi...   \n",
       "3786  https://api.github.com/users/yueyue4359/follow...   \n",
       "3787  https://api.github.com/users/hvm-uu/following{...   \n",
       "3788  https://api.github.com/users/2enyoasamoah/foll...   \n",
       "\n",
       "                                              gists_url  ... hooks_url  \\\n",
       "585   https://api.github.com/users/dhtaxonomy/gists{...  ...       NaN   \n",
       "593   https://api.github.com/users/CDH-SC/gists{/gis...  ...       NaN   \n",
       "599   https://api.github.com/users/adholibdh/gists{/...  ...       NaN   \n",
       "568   https://api.github.com/users/dhh21/gists{/gist...  ...       NaN   \n",
       "572   https://api.github.com/users/idrhku/gists{/gis...  ...       NaN   \n",
       "...                                                 ...  ...       ...   \n",
       "1153  https://api.github.com/users/XiaoyanYangAlice/...  ...       NaN   \n",
       "3785  https://api.github.com/users/ngonthier/gists{/...  ...       NaN   \n",
       "3786  https://api.github.com/users/yueyue4359/gists{...  ...       NaN   \n",
       "3787  https://api.github.com/users/hvm-uu/gists{/gis...  ...       NaN   \n",
       "3788  https://api.github.com/users/2enyoasamoah/gist...  ...       NaN   \n",
       "\n",
       "     issues_url members_url public_members_url description is_verified  \\\n",
       "585         NaN         NaN                NaN         NaN         NaN   \n",
       "593         NaN         NaN                NaN         NaN         NaN   \n",
       "599         NaN         NaN                NaN         NaN         NaN   \n",
       "568         NaN         NaN                NaN         NaN         NaN   \n",
       "572         NaN         NaN                NaN         NaN         NaN   \n",
       "...         ...         ...                ...         ...         ...   \n",
       "1153        NaN         NaN                NaN         NaN         NaN   \n",
       "3785        NaN         NaN                NaN         NaN         NaN   \n",
       "3786        NaN         NaN                NaN         NaN         NaN   \n",
       "3787        NaN         NaN                NaN         NaN         NaN   \n",
       "3788        NaN         NaN                NaN         NaN         NaN   \n",
       "\n",
       "     has_organization_projects has_repository_projects  double_check  \\\n",
       "585                        NaN                     NaN             1   \n",
       "593                        NaN                     NaN             1   \n",
       "599                        NaN                     NaN             1   \n",
       "568                        NaN                     NaN             1   \n",
       "572                        NaN                     NaN             1   \n",
       "...                        ...                     ...           ...   \n",
       "1153                       NaN                     NaN             1   \n",
       "3785                       NaN                     NaN             1   \n",
       "3786                       NaN                     NaN             1   \n",
       "3787                       NaN                     NaN             1   \n",
       "3788                       NaN                     NaN             1   \n",
       "\n",
       "     cleaned_search_query_time  \n",
       "585                 2023-03-19  \n",
       "593                 2023-03-19  \n",
       "599                 2023-03-19  \n",
       "568                 2023-03-19  \n",
       "572                 2023-03-19  \n",
       "...                        ...  \n",
       "1153                2023-03-19  \n",
       "3785                2022-11-19  \n",
       "3786                2022-11-19  \n",
       "3787                2022-11-12  \n",
       "3788                2022-11-12  \n",
       "\n",
       "[133 rows x 54 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "both          796\n",
       "right_only    133\n",
       "left_only       1\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df._merge.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "794\n"
     ]
    }
   ],
   "source": [
    "newer_counts = df.groupby(subset_fields).size().reset_index(name='new_counts')\n",
    "older_counts = older_df.groupby(subset_fields).size().reset_index(name='older_counts')\n",
    "merged_counts = pd.merge(newer_counts, older_counts, on=subset_fields, how='left')\n",
    "missing_values = merged_counts[(merged_counts.new_counts < merged_counts.older_counts) | (merged_counts.older_counts.isna())]\n",
    "missing_join = pd.merge(older_df, missing_values[subset_fields], on=subset_fields, how='inner')\n",
    "missing_join = missing_join.drop_duplicates(subset=subset_fields)\n",
    "print(len(missing_join))\n",
    "# double_check = missing_join[subset_fields]\n",
    "# combined_condition = np.ones(len(df), dtype=bool)\n",
    "# for field in subset_fields:\n",
    "#     combined_condition = combined_condition & df[field].isin(double_check[field])\n",
    "# df['double_check'] = np.where(combined_condition, 1, 0)\n",
    "# final_missing_values = df[(df.double_check == 0) & (df[subset_fields[0]].isin(double_check[subset_fields[0]]))]\n",
    "# print(len(final_missing_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(796, 927)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newer_counts), len(older_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>login</th>\n",
       "      <th>cleaned_search_query</th>\n",
       "      <th>new_counts</th>\n",
       "      <th>older_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1r3n3</td>\n",
       "      <td>https://api.github.com/search/users?q=Digital+...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ucyP</td>\n",
       "      <td>https://api.github.com/search/users?q=Digital+...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5colldh</td>\n",
       "      <td>https://api.github.com/search/users?q=Digital+...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABC-DH</td>\n",
       "      <td>https://api.github.com/search/users?q=Digital+...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADHO</td>\n",
       "      <td>https://api.github.com/search/users?q=Digital+...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>yrochat</td>\n",
       "      <td>https://api.github.com/search/users?q=Digital+...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>yukiyuqichen</td>\n",
       "      <td>https://api.github.com/search/users?q=Digital+...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>zimgraz</td>\n",
       "      <td>https://api.github.com/search/users?q=Digital+...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>zkmacdon</td>\n",
       "      <td>https://api.github.com/search/users?q=Digital+...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>zoharbuzaglo</td>\n",
       "      <td>https://api.github.com/search/users?q=Digital+...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>794 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            login                               cleaned_search_query  \\\n",
       "0           1r3n3  https://api.github.com/search/users?q=Digital+...   \n",
       "1           1ucyP  https://api.github.com/search/users?q=Digital+...   \n",
       "2         5colldh  https://api.github.com/search/users?q=Digital+...   \n",
       "3          ABC-DH  https://api.github.com/search/users?q=Digital+...   \n",
       "4            ADHO  https://api.github.com/search/users?q=Digital+...   \n",
       "..            ...                                                ...   \n",
       "791       yrochat  https://api.github.com/search/users?q=Digital+...   \n",
       "792  yukiyuqichen  https://api.github.com/search/users?q=Digital+...   \n",
       "793       zimgraz  https://api.github.com/search/users?q=Digital+...   \n",
       "794      zkmacdon  https://api.github.com/search/users?q=Digital+...   \n",
       "795  zoharbuzaglo  https://api.github.com/search/users?q=Digital+...   \n",
       "\n",
       "     new_counts  older_counts  \n",
       "0             1             2  \n",
       "1             1             2  \n",
       "2             1             2  \n",
       "3             1             2  \n",
       "4             1             2  \n",
       "..          ...           ...  \n",
       "791           1             2  \n",
       "792           1             2  \n",
       "793           1             2  \n",
       "794           1             2  \n",
       "795           1             2  \n",
       "\n",
       "[794 rows x 4 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_counts[(merged_counts.older_counts != merged_counts.new_counts) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = pd.concat([test2[['login', 'cleaned_search_query']], search_queries_user_join_df[['login', 'cleaned_search_query']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "https://api.github.com/search/users?q=Digital+Humanities&per_page=100       123\n",
       "https://api.github.com/search/users?q=Humanidades+digitales&per_page=100      7\n",
       "https://api.github.com/search/users?q=Humanidades+Digitais&per_page=100       2\n",
       "https://api.github.com/search/users?q=Digitaalhumanitaaria&per_page=100       1\n",
       "Name: cleaned_search_query, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2[(~test2.login.isin(search_queries_user_join_df.login))].cleaned_search_query.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://api.github.com/search/users?q=Humanidades+digitales&per_page=100'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_queries_user_join_df[search_queries_user_join_df.login == \"hdcaicyt\"].cleaned_search_query.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['https://api.github.com/search/users?q=Humanidades+digitales&per_page=100',\n",
       "       'https://api.github.com/search/users?q=Informatica+umanistica&per_page=100',\n",
       "       'https://api.github.com/search/users?q=Digital+Humanities&per_page=100'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_test[merged_test.type_search.isna()].cleaned_search_query.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>login</th>\n",
       "      <th>cleaned_search_query</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1r3n3</td>\n",
       "      <td>https://api.github.com/search/users?q=Digital+...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>johlei</td>\n",
       "      <td>https://api.github.com/search/users?q=Digital+...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>jessgrimmer</td>\n",
       "      <td>https://api.github.com/search/users?q=Digital+...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>jessprof</td>\n",
       "      <td>https://api.github.com/search/users?q=Humanida...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>jeyrena1</td>\n",
       "      <td>https://api.github.com/search/users?q=Digital+...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>aergithub</td>\n",
       "      <td>https://api.github.com/search/users?q=Digital+...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>agnesecam</td>\n",
       "      <td>https://api.github.com/search/users?q=Informat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>agustinjaramillo</td>\n",
       "      <td>https://api.github.com/search/users?q=Digital+...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>aiucd</td>\n",
       "      <td>https://api.github.com/search/users?q=Informat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>zoharbuzaglo</td>\n",
       "      <td>https://api.github.com/search/users?q=Digital+...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>929 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                login                               cleaned_search_query  \\\n",
       "0               1r3n3  https://api.github.com/search/users?q=Digital+...   \n",
       "624            johlei  https://api.github.com/search/users?q=Digital+...   \n",
       "612       jessgrimmer  https://api.github.com/search/users?q=Digital+...   \n",
       "613          jessprof  https://api.github.com/search/users?q=Humanida...   \n",
       "614          jeyrena1  https://api.github.com/search/users?q=Digital+...   \n",
       "..                ...                                                ...   \n",
       "314         aergithub  https://api.github.com/search/users?q=Digital+...   \n",
       "315         agnesecam  https://api.github.com/search/users?q=Informat...   \n",
       "316  agustinjaramillo  https://api.github.com/search/users?q=Digital+...   \n",
       "317             aiucd  https://api.github.com/search/users?q=Informat...   \n",
       "928      zoharbuzaglo  https://api.github.com/search/users?q=Digital+...   \n",
       "\n",
       "     counts  \n",
       "0         1  \n",
       "624       1  \n",
       "612       1  \n",
       "613       1  \n",
       "614       1  \n",
       "..      ...  \n",
       "314       1  \n",
       "315       1  \n",
       "316       1  \n",
       "317       1  \n",
       "928       1  \n",
       "\n",
       "[929 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2.groupby(subset_fields).size().reset_index(name='counts').sort_values(by=['counts'], ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if all items exist in entity files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 0, 0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_repos = search_queries_repo_join_df[~search_queries_repo_join_df.full_name.isin(repo_df.full_name)]\n",
    "missing_users = search_queries_user_join_df[(~search_queries_user_join_df.login.isin(user_df.login)) & (search_queries_user_join_df['type'] == 'User')]\n",
    "missing_orgs = search_queries_user_join_df[(~search_queries_user_join_df.login.isin(user_df.login)) & (search_queries_user_join_df['type'] == 'Organization')]\n",
    "\n",
    "len(missing_repos), len(missing_users), len(missing_orgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(missing_repos) > 0:\n",
    "    repo_df = check_add_repos(missing_repos, '../data/large_files/entity_files/repos_dataset.csv', True)\n",
    "if len(missing_orgs) > 0:\n",
    "    org_df = check_add_orgs(missing_orgs, '../data/entity_files/orgs_dataset.csv', True, False)\n",
    "if len(missing_users) > 0:\n",
    "    user_df = check_add_users(missing_users, '../data/entity_files/users_dataset.csv', True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2264, 667, 126)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_repos = pd.merge(repo_df, search_queries_repo_join_df[['full_name', 'finalized_language', 'keep_resource']], on='full_name', how='inner')\n",
    "core_repos = core_repos.drop_duplicates(subset=['full_name'])\n",
    "core_users = pd.merge(user_df, search_queries_user_join_df[['login', 'finalized_language', 'keep_resource']], on='login', how='inner')\n",
    "core_users = core_users.drop_duplicates(subset=['login'])\n",
    "core_orgs = core_users[core_users['type'] == 'Organization']\n",
    "core_users = core_users[core_users['type'] == 'User']\n",
    "\n",
    "len(core_repos), len(core_users), len(core_orgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_users.to_csv(\"../data/derived_files/initial_core_users.csv\", index=False)\n",
    "core_orgs.to_csv(\"../data/derived_files/initial_core_orgs.csv\", index=False)\n",
    "core_repos.to_csv(\"../data/derived_files/initial_core_repos.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "values_and_versions_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
