{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Initial Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from data_generation_scripts.utils import check_rate_limit, check_add_orgs, check_add_repos, check_add_users\n",
    "from data_generation_scripts.generate_expanded_search_data import get_initial_search_datasets\n",
    "from data_generation_scripts.generate_repo_metadata import get_repo_languages, get_repo_labels, get_repo_tags,  get_repo_profile, get_total_commits\n",
    "from data_generation_scripts.generate_repo_users_interactions import get_repos_user_actors\n",
    "from data_generation_scripts.generate_repo_metadata import check_total_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've run `generate_expanded_search_data.py` and then `check_clean_search_results.py` you'll have a series of files in the `data/` directory that contain the results of your search. This notebook will help you process those results into a single file that can be used for analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of how to run `generate_expanded_search_data.py`:\n",
    "\n",
    "```python3\n",
    "rates_df = check_rate_limit()\n",
    "initial_repo_output_path = \"../data/repo_data/\"\n",
    "repo_output_path = \"../data/large_files/entity_files/repos_dataset.csv\"\n",
    "repo_join_output_path = \"../data/large_files/join_files/search_queries_repo_join_dataset.csv\"\n",
    "\n",
    "initial_user_output_path = \"../data/user_data/\"\n",
    "user_output_path = \"../data/entity_files/users_dataset.csv\"\n",
    "user_join_output_path = \"../data/join_files/search_queries_user_join_dataset.csv\"\n",
    "load_existing_data = False\n",
    "overwrite_existing_temp_files = False\n",
    "org_output_path = \"../data/entity_files/orgs_dataset.csv\"\n",
    "\n",
    "get_initial_search_datasets(rates_df, initial_repo_output_path,  repo_output_path, repo_join_output_path, initial_user_output_path, user_output_path, user_join_output_path, org_output_path, overwrite_existing_temp_files, load_existing_data)\n",
    "```\n",
    "\n",
    "And then just run `check_clean_search_results.py` "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Initial Core Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.read_csv(\"../data/entity_files/users_dataset.csv\")\n",
    "repo_df = pd.read_csv(\"../data/large_files/entity_files/repos_dataset.csv\", low_memory=False)\n",
    "org_df = pd.read_csv(\"../data/entity_files/orgs_dataset.csv\", low_memory=False)\n",
    "search_queries_repo_join_df = pd.read_csv(\"../data/derived_files/updated_search_queries_repo_join_subset_dh_dataset.csv\")\n",
    "search_queries_user_join_df = pd.read_csv(\n",
    "    \"../data/derived_files/updated_search_queries_user_join_subset_dh_dataset.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial core datasets will be comprised of the following:\n",
    "\n",
    "- `core_repos`: A list of all repos that were returned by the search query\n",
    "- `core_users`: A list of all users that were returned by the search query\n",
    "- `core_orgs`: A list of all orgs that were returned by the search query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if all items exist in entity files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 0, 0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_repos = search_queries_repo_join_df[~search_queries_repo_join_df.full_name.isin(repo_df.full_name)]\n",
    "missing_users = search_queries_user_join_df[(~search_queries_user_join_df.login.isin(user_df.login)) & (search_queries_user_join_df['type'] == 'User')]\n",
    "missing_orgs = search_queries_user_join_df[(~search_queries_user_join_df.login.isin(user_df.login)) & (search_queries_user_join_df['type'] == 'Organization')]\n",
    "\n",
    "len(missing_repos), len(missing_users), len(missing_orgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of repos: 344846 1685119394.0542452\n",
      "Number of new repos: 0 1685119394.108879\n",
      "Number of repos: 344846 1685119395.7622678 inner else statement\n",
      "Number of repos: 344846, checking if older file exists 1685119395.7625248\n",
      "Repo file updated 1685119414.689198\n"
     ]
    }
   ],
   "source": [
    "if len(missing_repos) > 0:\n",
    "    repo_df = check_add_repos(missing_repos, '../data/large_files/entity_files/repos_dataset.csv', True)\n",
    "if len(missing_orgs) > 0:\n",
    "    org_df = check_add_orgs(missing_orgs, '../data/entity_files/orgs_dataset.csv', True, False)\n",
    "if len(missing_users) > 0:\n",
    "    user_df = check_add_users(missing_users, '../data/entity_files/users_dataset.csv', True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2264, 667, 126)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_repos = pd.merge(repo_df, search_queries_repo_join_df[['full_name', 'finalized_language', 'keep_resource']], on='full_name', how='inner')\n",
    "core_repos = core_repos.drop_duplicates(subset=['full_name'])\n",
    "core_users = pd.merge(user_df, search_queries_user_join_df[['login', 'finalized_language', 'keep_resource']], on='login', how='inner')\n",
    "core_users = core_users.drop_duplicates(subset=['login'])\n",
    "core_orgs = core_users[core_users['type'] == 'Organization']\n",
    "core_users = core_users[core_users['type'] == 'User']\n",
    "\n",
    "len(core_repos), len(core_users), len(core_orgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_users.to_csv(\"../data/derived_files/initial_core_users.csv\", index=False)\n",
    "core_orgs.to_csv(\"../data/derived_files/initial_core_orgs.csv\", index=False)\n",
    "core_repos.to_csv(\"../data/derived_files/initial_core_repos.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "values_and_versions_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
